Traceback (most recent call last):
  File "train.py", line 14, in <module>
    import lpips
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/lpips/__init__.py", line 11, in <module>
    from lpips.lpips import *
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/lpips/lpips.py", line 9, in <module>
    from . import pretrained_networks as pn
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/lpips/pretrained_networks.py", line 3, in <module>
    from torchvision import models as tv
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torchvision/__init__.py", line 6, in <module>
    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torchvision/models/__init__.py", line 2, in <module>
    from .convnext import *
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torchvision/models/convnext.py", line 8, in <module>
    from ..ops.misc import Conv2dNormActivation, Permute
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torchvision/ops/__init__.py", line 1, in <module>
    from ._register_onnx_ops import _register_custom_op
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torchvision/ops/_register_onnx_ops.py", line 5, in <module>
    from torch.onnx import symbolic_opset11 as opset11
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torch/onnx/__init__.py", line 46, in <module>
    from ._internal.exporter import (  # usort:skip. needs to be last to avoid circular import
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torch/onnx/_internal/exporter.py", line 42, in <module>
    from torch.onnx._internal.fx import (
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torch/onnx/_internal/fx/__init__.py", line 1, in <module>
    from .patcher import ONNXTorchPatcher
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/torch/onnx/_internal/fx/patcher.py", line 11, in <module>
    import transformers  # type: ignore[import]
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/transformers/__init__.py", line 26, in <module>
    from . import dependency_versions_check
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
    from .utils.versions import require_version, require_version_core
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/transformers/utils/__init__.py", line 21, in <module>
    from huggingface_hub import get_full_repo_name  # for backward compatibility
  File "<frozen importlib._bootstrap>", line 1039, in _handle_fromlist
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/huggingface_hub/__init__.py", line 547, in __getattr__
    submod = importlib.import_module(submod_path)
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/huggingface_hub/hf_api.py", line 63, in <module>
    from ._inference_endpoints import InferenceEndpoint, InferenceEndpointType
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/huggingface_hub/_inference_endpoints.py", line 39, in <module>
    class InferenceEndpoint:
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/site-packages/huggingface_hub/_inference_endpoints.py", line 236, in InferenceEndpoint
    accelerator: Optional[str] = None,
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/typing.py", line 258, in inner
    return cached(*args, **kwds)
  File "/home/ubuntu/miniconda3/envs/2dgs/lib/python3.8/typing.py", line 329, in __hash__
    def __hash__(self):
KeyboardInterrupt
